{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392775,"sourceType":"datasetVersion","datasetId":4297782},{"sourceId":7570342,"sourceType":"datasetVersion","datasetId":4407194},{"sourceId":7752462,"sourceType":"datasetVersion","datasetId":4382744},{"sourceId":7776446,"sourceType":"datasetVersion","datasetId":4550181},{"sourceId":7818976,"sourceType":"datasetVersion","datasetId":4417235}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":101.739864,"end_time":"2024-03-03T17:15:15.283704","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-03-03T17:13:33.54384","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import and Configuration","metadata":{}},{"cell_type":"code","source":"import os, random\nimport tensorflow as tf\nimport tensorflow\nimport tensorflow.keras.backend as K\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\nimport albumentations as albu\nfrom scipy.signal import butter, lfilter\nimport librosa\nfrom sklearn.model_selection import KFold, GroupKFold\nimport tensorflow.keras.backend as K, gc\nfrom tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate, LayerNormalization","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:36.447021Z","iopub.execute_input":"2024-03-11T21:18:36.448012Z","iopub.status.idle":"2024-03-11T21:18:49.946036Z","shell.execute_reply.started":"2024-03-11T21:18:36.447961Z","shell.execute_reply":"2024-03-11T21:18:49.944980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOAD_MODELS_FROM = '/kaggle/input/features-head-starter-models'\nTARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\nVER_K = 43 # Kaggle's spectrogram model version\nVER_E = 42 # EEG's spectrogram model version\nVER_R = 37 # EEG's Raw wavenet model version, trained on single GPU\nVER_KE = 47 # Kaggle's and EEG's spectrogram model version\nVER_KR = 48 # Kaggle's spectrogram and Raw model version\nVER_ER = 49 # EEG's spectrogram and Raw model version\nVER_KER = 50 # EEG's, Kaggle's spectrograms and Raw model version","metadata":{"papermill":{"duration":15.019425,"end_time":"2024-03-03T17:13:52.258732","exception":false,"start_time":"2024-03-03T17:13:37.239307","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-11T21:18:49.948222Z","iopub.execute_input":"2024-03-11T21:18:49.948894Z","iopub.status.idle":"2024-03-11T21:18:49.954891Z","shell.execute_reply.started":"2024-03-11T21:18:49.948861Z","shell.execute_reply":"2024-03-11T21:18:49.953936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seeds\nnp.random.seed(42)\nrandom.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:49.955956Z","iopub.execute_input":"2024-03-11T21:18:49.956744Z","iopub.status.idle":"2024-03-11T21:18:49.979506Z","shell.execute_reply.started":"2024-03-11T21:18:49.956713Z","shell.execute_reply":"2024-03-11T21:18:49.978362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE SINGLE GPU, MULTIPLE GPUS \ngpus = tf.config.list_physical_devices('GPU')\n# WE USE MIXED PRECISION\ntf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nif len(gpus)>1:\n    strategy = tf.distribute.MirroredStrategy()\n    print(f'Using {len(gpus)} GPUs')\nelse:\n    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n    print(f'Using {len(gpus)} GPU')","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:49.981869Z","iopub.execute_input":"2024-03-11T21:18:49.982138Z","iopub.status.idle":"2024-03-11T21:18:50.011930Z","shell.execute_reply.started":"2024-03-11T21:18:49.982114Z","shell.execute_reply":"2024-03-11T21:18:50.011193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data generator\nThis data generator outputs 512x512x3, the spectrogram and eeg images are concatenated all togother in a single image. For using data augmention you can set `augment = True` when creating the train data generator.","metadata":{"papermill":{"duration":0.007968,"end_time":"2024-03-03T17:13:52.37087","exception":false,"start_time":"2024-03-03T17:13:52.362902","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from abc import ABC, abstractmethod \n  \nFEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\nFEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\nFEATS = [['Fp1','F7','T3','T5','O1'],\n         ['Fp1','F3','C3','P3','O1'],\n         ['Fp2','F8','T4','T6','O2'],\n         ['Fp2','F4','C4','P4','O2']]\nUSE_PROCESSED = True # Use processed downsampled Raw EEG \n    \nclass BaseDataGenerator():\n    'Generates data for Keras'\n    def __init__(self, data, specs, eeg_specs, raw_eegs, augment, mode, data_type): \n        self.data = data\n        self.augment = augment\n        self.mode = mode\n        self.data_type = data_type\n        self.specs = specs\n        self.eeg_specs = eeg_specs\n        self.raw_eegs = raw_eegs\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, index):\n        X, y = self.data_generation(index)\n        if self.augment: X = self.augmentation(X)\n        return X, y\n    \n    def __call__(self):\n        for i in range(self.__len__()):\n            yield self.__getitem__(i)\n            \n            if i == self.__len__()-1:\n                self.on_epoch_end()\n                \n    def on_epoch_end(self):\n        if self.mode=='train': \n            self.data = self.data.sample(frac=1).reset_index(drop=True)\n    \n    # Abstract method generate data based on the trained data type\n    @abstractmethod\n    def data_generation(self, index):\n        pass\n        \n    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n        nyquist = 0.5 * sampling_rate\n        normal_cutoff = cutoff_freq / nyquist\n        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n        filtered_data = lfilter(b, a, data, axis=0)\n        return filtered_data\n    \n    def resize(self, img,size):\n        composition = albu.Compose([\n                albu.Resize(size[0],size[1])\n            ])\n        return composition(image=img)['image']\n            \n    def augmentation(self, img):\n        composition = albu.Compose([\n                albu.HorizontalFlip(p=0.4)\n            ])\n        return composition(image=img)['image']","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.013069Z","iopub.execute_input":"2024-03-11T21:18:50.013606Z","iopub.status.idle":"2024-03-11T21:18:50.025245Z","shell.execute_reply.started":"2024-03-11T21:18:50.013579Z","shell.execute_reply":"2024-03-11T21:18:50.024540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implementation class generates the data based on the data_type \nclass DataGenerator(BaseDataGenerator):\n    'Generates data for Keras'\n    def __init__(self, data, specs, eeg_specs, raw_eegs, augment, \n                 mode, data_type): \n        super().__init__(data, specs, eeg_specs, raw_eegs, augment, mode, data_type)\n    \n    def data_generation(self, index):\n        if self.data_type == 'KE':\n            X,y = self.generate_all_specs(index)\n        elif self.data_type == 'E' or self.data_type == 'K':\n            X,y = self.generate_specs(index)\n        elif self.data_type == 'R':\n            X,y = self.generate_raw(index)\n        elif self.data_type in ['ER','KR']:\n            X1,y = self.generate_specs(index)\n            X2,y = self.generate_raw(index)\n            X = (X1,X2)\n        elif self.data_type == 'KER':\n            X1,y = self.generate_all_specs(index)\n            X2,y = self.generate_raw(index)\n            X = (X1,X2)\n        return X,y\n    \n    def generate_all_specs(self, index):\n        X = np.zeros((512,512,3),dtype='float32')\n        y = np.zeros((6,),dtype='float32')\n        \n        row = self.data.iloc[index]\n        if self.mode=='test': \n            offset = 0\n        else:\n            offset = int(row.offset/2)\n        \n        eeg = self.eeg_specs[row.eeg_id]\n        spec = self.specs[row.spec_id]\n        \n        imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n        img = np.stack(imgs,axis=-1)\n        # LOG TRANSFORM SPECTROGRAM\n        img = np.clip(img,np.exp(-4),np.exp(8))\n        img = np.log(img)\n            \n        # STANDARDIZE PER IMAGE\n        img = np.nan_to_num(img, nan=0.0)    \n            \n        mn = img.flatten().min()\n        mx = img.flatten().max()\n        ep = 1e-5\n        img = 255 * (img - mn) / (mx - mn + ep)\n        \n        X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n        X[100+56:200+56,:256,0] = img[:,22:-22,2] # RL_k\n        X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # LP_k\n        X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n        X[0_0+56:100+56,:256,2] = img[:,22:-22,2] # RL_k\n        X[100+56:200+56,:256,2] = img[:,22:-22,1] # LP_k\n        \n        X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n        X[100+56:200+56,256:,0] = img[:,22:-22,2] # RL_k\n        X[0_0+56:100+56,256:,1] = img[:,22:-22,1] # LP_k\n        X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n        \n        # EEG\n        img = eeg\n        mn = img.flatten().min()\n        mx = img.flatten().max()\n        ep = 1e-5\n        img = 255 * (img - mn) / (mx - mn + ep)\n        X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n        X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n        X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n        X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n        X[200+56:300+56,:256,2] = img[:,22:-22,2] # RL_e\n        X[300+56:400+56,:256,2] = img[:,22:-22,1] # LP_e\n        \n        X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n        X[300+56:400+56,256:,0] = img[:,22:-22,2] # RL_e\n        X[200+56:300+56,256:,1] = img[:,22:-22,1] # LP_e\n        X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n\n        if self.mode!='test':\n            y[:] = row[TARGETS]\n        \n        return X,y\n    \n    def generate_specs(self, index):\n        X = np.zeros((512,512,3),dtype='float32')\n        y = np.zeros((6,),dtype='float32')\n        \n        row = self.data.iloc[index]\n        if self.mode=='test': \n            offset = 0\n        else:\n            offset = int(row.offset/2)\n            \n        if self.data_type in ['E','ER']:\n            img = self.eeg_specs[row.eeg_id]\n        elif self.data_type in ['K','KR']:\n            spec = self.specs[row.spec_id]\n            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n            img = np.stack(imgs,axis=-1)\n            # LOG TRANSFORM SPECTROGRAM\n            img = np.clip(img,np.exp(-4),np.exp(8))\n            img = np.log(img)\n            \n            # STANDARDIZE PER IMAGE\n            img = np.nan_to_num(img, nan=0.0)    \n            \n        mn = img.flatten().min()\n        mx = img.flatten().max()\n        ep = 1e-5\n        img = 255 * (img - mn) / (mx - mn + ep)\n        \n        X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n        X[100+56:200+56,:256,0] = img[:,22:-22,2]\n        X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n        X[100+56:200+56,:256,1] = img[:,22:-22,3]\n        X[0_0+56:100+56,:256,2] = img[:,22:-22,2]\n        X[100+56:200+56,:256,2] = img[:,22:-22,1]\n        \n        X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n        X[100+56:200+56,256:,0] = img[:,22:-22,1]\n        X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n        X[100+56:200+56,256:,1] = img[:,22:-22,3]\n        \n        X[200+56:300+56,:256,0] = img[:,22:-22,0]\n        X[300+56:400+56,:256,0] = img[:,22:-22,1]\n        X[200+56:300+56,:256,1] = img[:,22:-22,2]\n        X[300+56:400+56,:256,1] = img[:,22:-22,3]\n        X[200+56:300+56,:256,2] = img[:,22:-22,3]\n        X[300+56:400+56,:256,2] = img[:,22:-22,2]\n        \n        X[200+56:300+56,256:,0] = img[:,22:-22,0]\n        X[300+56:400+56,256:,0] = img[:,22:-22,2]\n        X[200+56:300+56,256:,1] = img[:,22:-22,1]\n        X[300+56:400+56,256:,1] = img[:,22:-22,3]\n        \n        if self.mode!='test':\n            y[:] = row[TARGETS]\n        \n        return X,y\n    \n    def generate_raw(self,index):\n        if USE_PROCESSED and self.mode!='test':\n            X = np.zeros((2_000,8),dtype='float32')\n            y = np.zeros((6,),dtype='float32')\n            row = self.data.iloc[index]\n            X = self.raw_eegs[row.eeg_id]\n            y[:] = row[TARGETS]\n            return X,y\n        \n        X = np.zeros((10_000,8),dtype='float32')\n        y = np.zeros((6,),dtype='float32')\n        \n        row = self.data.iloc[index]\n        eeg = self.raw_eegs[row.eeg_id]\n            \n        # FEATURE ENGINEER\n        X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n        X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n            \n        X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n        X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n            \n        X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n        X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n            \n        X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n        X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n            \n        # STANDARDIZE\n        X = np.clip(X,-1024,1024)\n        X = np.nan_to_num(X, nan=0) / 32.0\n            \n        # BUTTER LOW-PASS FILTER\n        X = self.butter_lowpass_filter(X)\n        # Downsample\n        X = X[::5,:]\n        \n        if self.mode!='test':\n            y[:] = row[TARGETS]\n                \n        return X,y","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.026668Z","iopub.execute_input":"2024-03-11T21:18:50.027283Z","iopub.status.idle":"2024-03-11T21:18:50.064097Z","shell.execute_reply.started":"2024-03-11T21:18:50.027252Z","shell.execute_reply":"2024-03-11T21:18:50.063110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create the dataset from data generator","metadata":{}},{"cell_type":"code","source":"def create_dataset(data, mode, data_type, specs, eeg_specs, raw_eegs,\n                   batch_size=8, augment=False):    \n    if data_type in ['K','E','KE']: \n        inp = tf.TensorSpec(shape=(512,512,3), dtype=tf.float32)\n    elif data_type in ['KR','ER','KER']:\n        inp = (tf.TensorSpec(shape=(512,512,3), dtype=tf.float32), \n               tf.TensorSpec(shape=(2000,8), dtype=tf.float32))\n    elif data_type in ['R']:\n        inp = tf.TensorSpec(shape=(2000,8), dtype=tf.float32)\n\n    output_signature = (inp, tf.TensorSpec(shape=(6,), dtype=tf.float32))\n    \n    # Create the data generator\n    gen = DataGenerator(data, specs, eeg_specs, raw_eegs, augment, mode, data_type)\n    # Create the dataset from data generator\n    dataset = tf.data.Dataset.from_generator(generator=gen,\n                                             output_signature=output_signature).batch(batch_size * strategy.num_replicas_in_sync)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.065435Z","iopub.execute_input":"2024-03-11T21:18:50.065844Z","iopub.status.idle":"2024-03-11T21:18:50.077861Z","shell.execute_reply.started":"2024-03-11T21:18:50.065815Z","shell.execute_reply":"2024-03-11T21:18:50.077203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data loading function","metadata":{"papermill":{"duration":0.008533,"end_time":"2024-03-03T17:13:54.87667","exception":false,"start_time":"2024-03-03T17:13:54.868137","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def spectrogram_from_eeg(parquet_path):    \n    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n    eeg = pd.read_parquet(parquet_path)\n    middle = (len(eeg)-10_000)//2\n    eeg = eeg.iloc[middle:middle+10_000]\n    \n    # VARIABLE TO HOLD SPECTROGRAM\n    img = np.zeros((100,300,4) ,dtype='float32')\n\n    for k in range(4):\n        COLS = FEATS[k]\n        \n        for kk in range(4):\n            # FILL NANS\n            x1 = eeg[COLS[kk]].values\n            x2 = eeg[COLS[kk+1]].values\n            m = np.nanmean(x1)\n            if np.isnan(x1).mean()<1: \n                x1 = np.nan_to_num(x1,nan=m)\n            else: \n                x1[:] = 0\n            m = np.nanmean(x2)\n            if np.isnan(x2).mean()<1: \n                x2 = np.nan_to_num(x2,nan=m)\n            else: \n                x2[:] = 0\n                \n            # COMPUTE PAIR DIFFERENCES\n            x = x1 - x2\n\n            # RAW SPECTROGRAM\n            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//300, \n                                  n_fft=1024, n_mels=100, fmin=0, fmax=20, win_length=128)\n            \n            # LOG TRANSFORM\n            width = (mel_spec.shape[1]//30)*30\n            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n            img[:,:,k] += mel_spec_db\n                \n        # AVERAGE THE 4 MONTAGE DIFFERENCES\n        img[:,:,k] /= 4.0\n    return img\n# Read EEG from par files\ndef eeg_from_parquet(parquet_path):\n    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n    rows = len(eeg)\n    offset = (rows-10_000)//2\n    eeg = eeg.iloc[offset:offset+10_000]\n    data = np.zeros((10_000,len(FEATS2)))\n    for j,col in enumerate(FEATS2):\n        \n        # FILL NAN\n        x = eeg[col].values.astype('float32')\n        m = np.nanmean(x)\n        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n        else: x[:] = 0\n        \n        data[:,j] = x\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.078721Z","iopub.execute_input":"2024-03-11T21:18:50.079548Z","iopub.status.idle":"2024-03-11T21:18:50.089835Z","shell.execute_reply.started":"2024-03-11T21:18:50.079524Z","shell.execute_reply":"2024-03-11T21:18:50.089004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the models","metadata":{}},{"cell_type":"code","source":"# Setup for ensemble\nLOAD_BACKBONE_FROM = '/kaggle/input/efficientnetb-tf-keras/EfficientNetB2.h5'","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.090716Z","iopub.execute_input":"2024-03-11T21:18:50.090966Z","iopub.status.idle":"2024-03-11T21:18:50.105210Z","shell.execute_reply.started":"2024-03-11T21:18:50.090936Z","shell.execute_reply":"2024-03-11T21:18:50.104074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SPECModel:\n    def __init__(self, hybrid=False):\n        self.hybrid = hybrid\n        self.build_model()\n        \n    def get_model(self):\n        return self.model\n        \n    def build_model(self):\n        inp = tf.keras.layers.Input((512,512,3))\n        base_model = load_model(f'{LOAD_BACKBONE_FROM}')    \n        x = base_model(inp)\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        if not self.hybrid:\n            x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n        # Create the model\n        self.model = tf.keras.Model(inputs=inp, outputs=x)\n        opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n        loss = tf.keras.losses.KLDivergence()\n        self.model.compile(loss=loss, optimizer=opt)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.108222Z","iopub.execute_input":"2024-03-11T21:18:50.108566Z","iopub.status.idle":"2024-03-11T21:18:50.119948Z","shell.execute_reply.started":"2024-03-11T21:18:50.108537Z","shell.execute_reply":"2024-03-11T21:18:50.118857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WAVEModel(SPECModel):\n    def __init__(self, hybrid=False):\n        self.hybrid = hybrid\n        self.build_model()\n        \n    def wave_block(self, x, filters, kernel_size, n):\n        dilation_rates = [2**i for i in range(n)]\n        x = Conv1D(filters = filters,\n                   kernel_size = 1,\n                   padding = 'same')(x)\n        res_x = x\n        for dilation_rate in dilation_rates:\n            tanh_out = Conv1D(filters = filters,\n                              kernel_size = kernel_size,\n                              padding = 'same', \n                              activation = 'tanh', \n                              dilation_rate = dilation_rate)(x)\n            sigm_out = Conv1D(filters = filters,\n                              kernel_size = kernel_size,\n                              padding = 'same',\n                              activation = 'sigmoid', \n                              dilation_rate = dilation_rate)(x)\n            x = Multiply()([tanh_out, sigm_out])\n            x = Conv1D(filters = filters,\n                       kernel_size = 1,\n                       padding = 'same')(x)\n            res_x = Add()([res_x, x])\n        return res_x\n        \n    def build_model(self):\n        # INPUT \n        inp = tf.keras.Input(shape=(2_000,8))\n\n        ############\n        # FEATURE EXTRACTION SUB MODEL\n        inp2 = tf.keras.Input(shape=(2_000,1))\n        x = self.wave_block(inp2, 8, 4, 6)\n        x = self.wave_block(x, 16, 4, 6)\n        x = self.wave_block(x, 32, 4, 6)\n        x = self.wave_block(x, 64, 4, 6)\n        model2 = tf.keras.Model(inputs=inp2, outputs=x)\n        ###########\n\n        # LEFT TEMPORAL CHAIN\n        x1 = model2(inp[:,:,0:1])\n        x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n        x2 = model2(inp[:,:,1:2])\n        x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n        z1 = tf.keras.layers.Average()([x1,x2])\n\n        # LEFT PARASAGITTAL CHAIN\n        x1 = model2(inp[:,:,2:3])\n        x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n        x2 = model2(inp[:,:,3:4])\n        x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n        z2 = tf.keras.layers.Average()([x1,x2])\n\n        # RIGHT PARASAGITTAL CHAIN\n        x1 = model2(inp[:,:,4:5])\n        x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n        x2 = model2(inp[:,:,5:6])\n        x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n        z3 = tf.keras.layers.Average()([x1,x2])\n\n        # RIGHT TEMPORAL CHAIN\n        x1 = model2(inp[:,:,6:7])\n        x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n        x2 = model2(inp[:,:,7:8])\n        x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n        z4 = tf.keras.layers.Average()([x1,x2])\n\n        # COMBINE CHAINS\n        y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\n        if not self.hybrid:\n            y = tf.keras.layers.Dense(64, activation='relu')(y)\n            y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n\n        # COMPILE MODEL\n        self.model = tf.keras.Model(inputs=inp, outputs=y)\n        opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n        loss = tf.keras.losses.KLDivergence()\n        self.model.compile(loss=loss, optimizer = opt)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.121769Z","iopub.execute_input":"2024-03-11T21:18:50.122451Z","iopub.status.idle":"2024-03-11T21:18:50.137011Z","shell.execute_reply.started":"2024-03-11T21:18:50.122410Z","shell.execute_reply":"2024-03-11T21:18:50.135825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HYBRIDModel(SPECModel):\n    def __init__(self):\n        self.build_model()      \n        \n    def build_model(self):\n        model_spec = SPECModel(True).model\n        model_wave = WAVEModel(True).model\n        inputs = [model_spec.input, model_wave.input]\n        x = [model_spec.output, model_wave.output]\n        x = tf.keras.layers.Concatenate()(x)\n        x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n\n        # COMPILE MODEL\n        self.model = tf.keras.Model(inputs=inputs, outputs=x)\n        opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n        loss = tf.keras.losses.KLDivergence()\n        self.model.compile(loss=loss, optimizer = opt)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.138604Z","iopub.execute_input":"2024-03-11T21:18:50.139182Z","iopub.status.idle":"2024-03-11T21:18:50.153635Z","shell.execute_reply.started":"2024-03-11T21:18:50.139135Z","shell.execute_reply":"2024-03-11T21:18:50.152631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_spec = SPECModel().get_model()\nmodel_wave = WAVEModel().get_model()\nmodel_hybrid = HYBRIDModel().get_model()\nprint(model_spec)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:18:50.154655Z","iopub.execute_input":"2024-03-11T21:18:50.155006Z","iopub.status.idle":"2024-03-11T21:19:13.254675Z","shell.execute_reply.started":"2024-03-11T21:18:50.154973Z","shell.execute_reply":"2024-03-11T21:19:13.253647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"# Load training data\ndef add_kl(data):\n    labels = data[TARGETS].values + 1e-5\n    data['kl'] = tf.keras.losses.KLDivergence(reduction='none')(\n        np.array([[1/6]*6]*len(data)),labels)\n    return data\n    \n\ntrain = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n\nMETA = ['spectrogram_id','spectrogram_label_offset_seconds','patient_id','expert_consensus']\ntrain = train.groupby('eeg_id')[META+TARGETS\n                       ].agg({**{m:'first' for m in META},**{t:'sum' for t in TARGETS}}).reset_index() \ntrain[TARGETS] = train[TARGETS]/train[TARGETS].values.sum(axis=1,keepdims=True)\ntrain.columns = ['eeg_id','spec_id','offset','patient_id','target'] + TARGETS\ntrain = add_kl(train)\ndisplay(train.head(3))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:19:13.256122Z","iopub.execute_input":"2024-03-11T21:19:13.256467Z","iopub.status.idle":"2024-03-11T21:19:13.532349Z","shell.execute_reply.started":"2024-03-11T21:19:13.256436Z","shell.execute_reply":"2024-03-11T21:19:13.531456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold, GroupKFold\nimport tensorflow.keras.backend as K, gc\n\n# Submission ON TEST with an individual\ndef preds_with_a_model():\n    all_oof = []\n    all_true = []\n    losses = []\n    val_losses = []\n    total_hist = {}\n\n    gkf = GroupKFold(n_splits=5)\n    for i, (_, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):   \n        print(f'### Fold {i+1}')\n        val_df = train.iloc[valid_index]\n        val_dataset = create_dataset(val_df, data_type='KER', mode='train')\n        print(f'valid size {len(valid_index)}')\n        # EEG's, Kaggle's spectrograms and Raw model\n        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KER_{VER_KER}_{i}.weights.h5')\n        oof = model_hybrid.predict(val_dataset, verbose=1)\n        print(oof)\n        all_oof.append(oof)\n        all_true.append(train.iloc[valid_index][TARGETS].values)    \n        del model, oof\n        gc.collect()\n\n\n    all_oof = np.concatenate(all_oof)\n    all_true = np.concatenate(all_true)\n    print(f'CV KL SCORE: {score(all_true,all_oof)}')","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:19:13.533985Z","iopub.execute_input":"2024-03-11T21:19:13.534477Z","iopub.status.idle":"2024-03-11T21:19:13.542711Z","shell.execute_reply.started":"2024-03-11T21:19:13.534445Z","shell.execute_reply":"2024-03-11T21:19:13.541305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make predictions using an ensemble of models","metadata":{}},{"cell_type":"markdown","source":"## Load testing data","metadata":{}},{"cell_type":"code","source":"# Load testing features\ntest = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n# Rename\ntest = test.rename({'spectrogram_id':'spec_id'},axis=1)\nprint('Test shape',test.shape)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:19:13.544012Z","iopub.execute_input":"2024-03-11T21:19:13.544353Z","iopub.status.idle":"2024-03-11T21:19:13.565763Z","shell.execute_reply.started":"2024-03-11T21:19:13.544324Z","shell.execute_reply":"2024-03-11T21:19:13.565105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read all spectrograms\nPATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms'\nfiles = os.listdir(PATH)\nprint(f'There are {len(files)} test spectrogram parquets')\ntest_specs = {}\nfor i,f in enumerate(files):\n    tmp = pd.read_parquet(f'{PATH}/{f}')\n    name = int(f.split('.')[0])\n    test_specs[name] = tmp.iloc[:,1:].values","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:19:13.566599Z","iopub.execute_input":"2024-03-11T21:19:13.567327Z","iopub.status.idle":"2024-03-11T21:19:13.718482Z","shell.execute_reply.started":"2024-03-11T21:19:13.567302Z","shell.execute_reply":"2024-03-11T21:19:13.717596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read all EEG Spectrograms\nPATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\nDISPLAY = 0\nEEG_IDS = test.eeg_id.unique()\ntest_eeg_specs = {}\nprint('Converting Test EEG to Spectrograms...')\nfor i,eeg_id in enumerate(EEG_IDS):\n    # CREATE SPECTROGRAM FROM EEG PARQUET\n    test_eeg_specs[eeg_id] = spectrogram_from_eeg(f'{PATH}/{eeg_id}.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:19:13.719747Z","iopub.execute_input":"2024-03-11T21:19:13.720272Z","iopub.status.idle":"2024-03-11T21:19:23.622333Z","shell.execute_reply.started":"2024-03-11T21:19:13.720240Z","shell.execute_reply":"2024-03-11T21:19:23.621536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read all RAW EEG Signals\ntest_raw_eegs = {}\nEEG_IDS = test.eeg_id.unique()\nPATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\nprint('Processing Test EEG parquets...')\nfor i,eeg_id in enumerate(EEG_IDS):\n    # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n    test_raw_eegs[eeg_id] = eeg_from_parquet(f'{PATH}/{eeg_id}.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-03-11T21:19:23.623615Z","iopub.execute_input":"2024-03-11T21:19:23.624773Z","iopub.status.idle":"2024-03-11T21:19:23.642198Z","shell.execute_reply.started":"2024-03-11T21:19:23.624744Z","shell.execute_reply":"2024-03-11T21:19:23.641467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Infer with an ensemble of 7 models","metadata":{}},{"cell_type":"code","source":"LBs = [0.41,0.39,0.41,0.37,0.39,0.38,0.36] # K|E|R|KE|KR|ER|KER for weighted ensemble we use LBs of each model\n# Submission ON TEST with ensemble\ndef preds_with_ensemble():\n    preds = []\n    # LB SCORE WEIGHTS FOR EACH MODEL\n    lbs = 1 - np.array(LBs)\n    weights = lbs/lbs.sum()\n    params = {'specs':test_specs, 'eeg_specs':test_eeg_specs, 'raw_eegs':test_raw_eegs}\n    test_dataset_K = create_dataset(test, data_type='K', mode='test', **params)\n    test_dataset_E = create_dataset(test, data_type='E', mode='test', **params)\n    test_dataset_R = create_dataset(test, data_type='R', mode='test', **params)\n    test_dataset_KE = create_dataset(test, data_type='KE', mode='test', **params)\n    test_dataset_KR = create_dataset(test, data_type='KR', mode='test', **params)\n    test_dataset_ER = create_dataset(test, data_type='ER', mode='test', **params)\n    test_dataset_KER = create_dataset(test, data_type='KER', mode='test', **params)\n    \n    for i in range(5):\n        print(f'Fold {i+1}')\n        # Kaggle's spectrogram model \n        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_K_{VER_K}_{i}.weights.h5')\n        pred_K = model_spec.predict(test_dataset_K, verbose=1)\n        # EEG's spectrogram model\n        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_E_{VER_E}_{i}.weights.h5')\n        pred_E = model_spec.predict(test_dataset_E, verbose=1)\n        # EEG's Raw wavenet model\n        model_wave.load_weights(f'{LOAD_MODELS_FROM}/model_R_{VER_R}_{i}.weights.h5')\n        pred_R = model_wave.predict(test_dataset_R, verbose=1)\n        # Kaggle's and EEG's spectrogram model\n        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_KE_{VER_KE}_{i}.weights.h5')\n        pred_KE = model_spec.predict(test_dataset_KE, verbose=1)\n        # Kaggle's spectrogram and Raw model\n        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KR_{VER_KR}_{i}.weights.h5')\n        pred_KR = model_hybrid.predict(test_dataset_KR, verbose=1)\n        # EEG's spectrogram and Raw model\n        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_ER_{VER_ER}_{i}.weights.h5')\n        pred_ER = model_hybrid.predict(test_dataset_ER, verbose=1)\n        # EEG's, Kaggle's spectrograms and Raw model\n        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KER_{VER_KER}_{i}.weights.h5')\n        pred_KER = model_hybrid.predict(test_dataset_KER, verbose=1)\n        # Combine the predictions from all the model with different weights \n        pred = np.array([pred_K,pred_E,pred_R,pred_KE,pred_KR,pred_ER,pred_KER])\n        pred = np.average(pred,axis=0,weights=weights)\n        preds.append(pred)\n        \n    pred = np.mean(preds,axis=0)\n    return pred\n# Prediction with \npred = preds_with_ensemble()\nprint('Test preds shape',pred.shape)","metadata":{"papermill":{"duration":66.385954,"end_time":"2024-03-03T17:15:12.067289","exception":false,"start_time":"2024-03-03T17:14:05.681335","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-11T21:19:23.643535Z","iopub.execute_input":"2024-03-11T21:19:23.644083Z","iopub.status.idle":"2024-03-11T21:20:57.074550Z","shell.execute_reply.started":"2024-03-11T21:19:23.644052Z","shell.execute_reply":"2024-03-11T21:20:57.073747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Submission CSV","metadata":{}},{"cell_type":"code","source":"sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\nsub[TARGETS] = pred\nsub.to_csv('submission.csv',index=False)\nprint('Submissionn shape',sub.shape)\ndisplay(sub)","metadata":{"papermill":{"duration":0.030287,"end_time":"2024-03-03T17:15:12.110333","exception":false,"start_time":"2024-03-03T17:15:12.080046","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-11T21:20:57.075524Z","iopub.execute_input":"2024-03-11T21:20:57.076156Z","iopub.status.idle":"2024-03-11T21:20:57.093614Z","shell.execute_reply.started":"2024-03-11T21:20:57.076132Z","shell.execute_reply":"2024-03-11T21:20:57.092677Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\nprint(sub.iloc[:,-6:].sum(axis=1).to_string())","metadata":{"papermill":{"duration":0.020742,"end_time":"2024-03-03T17:15:12.143017","exception":false,"start_time":"2024-03-03T17:15:12.122275","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-11T21:20:57.095391Z","iopub.execute_input":"2024-03-11T21:20:57.095742Z","iopub.status.idle":"2024-03-11T21:20:57.103675Z","shell.execute_reply.started":"2024-03-11T21:20:57.095712Z","shell.execute_reply":"2024-03-11T21:20:57.102705Z"},"trusted":true},"execution_count":null,"outputs":[]}]}